{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6240c5ad",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbe2f2",
   "metadata": {},
   "source": [
    "### Old work related to the paper ' Convolutional Neural Networks for Sentence Classification ' \n",
    "- https://arxiv.org/pdf/1408.5882.pdf\n",
    "\n",
    "It train a simple (CNN) with one layer of convolution on top of word vectors obtained from an unsupervised neural language model. These vectors were trained by Mikolov etal. (2013) on 100 billion words of Google News, and are publicly available.1 We initially keep the word vectors static and learn only the other parameters of the model. Despite little tuning of hyperparameters, this simple model achieves excellent results on multiple benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc9a1f",
   "metadata": {},
   "source": [
    "# What is new work we add on the old one and our contributions?\n",
    "\n",
    "Instead of unsing only the CNN to make the Sentence Classification we will use CNN in as well as LSTM to generate a combination model of them( CNN-LSTM ) and ( LSTM-CNN )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c9aec",
   "metadata": {},
   "source": [
    "# CNNs\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are networks initially created for image-related tasks that can learn to capture specific features regardless of locality.\n",
    "\n",
    "For a more concrete example of that, imagine we use CNNs to distinguish pictures of Cars vs. pictures of Dogs. Since CNNs learn to capture features regardless of where these might be, the CNN will learn that cars have wheels, and every time it sees a wheel, regardless of where it is on the picture, that feature will activate.\n",
    "\n",
    "In our particular case, it could capture a negative phrase such as \"don't like\" regardless of where it happens in the tweet.\n",
    "\n",
    "*     I don't like watching those types of films\n",
    "*     That's the one thing I really don't like.\n",
    "*     I saw the movie, and I don't like how it ended.\n",
    "\n",
    "![image.png](CNNs.png)\n",
    "\n",
    "\n",
    "# LSTMs\n",
    "\n",
    "Long-Term Short Term Memory (LSTMs) are a type of network that has a memory that \"remembers\" previous data from the input and makes decisions based on that knowledge. These networks are more directly suited for written data inputs, since each word in a sentence has meaning based on the surrounding words (previous and upcoming words).\n",
    "\n",
    "In our particular case, it is possible that an LSTM could allow us to capture changing sentiment in a tweet. For example, a sentence such as: At first I loved it, but then I ended up hating it. has words with conflicting sentiments that would end-up confusing a simple Feed-Forward network. The LSTM, on the other hand, could learn that sentiments expressed towards the end of a sentence mean more than those expressed at the start.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9560fa08",
   "metadata": {},
   "source": [
    "# CNN-LSTM Model\n",
    "\n",
    "The first model I tried was the CNN-LSTM Model. Our CNN-LSTM model combination consists of an initial convolution layer which will receive word embeddings as input. Its output will then be pooled to a smaller dimension which is then fed into an LSTM layer. The intuition behind this model is that the convolution layer will extract local features and the LSTM layer will then be able to use the ordering of said features to learn about the input’s text ordering. In practice, this model is not as powerful as our other LSTM-CNN model proposed.\n",
    "![image.png](CNN-LSTM_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9308ce",
   "metadata": {},
   "source": [
    "# LSTM-CNN Model\n",
    "\n",
    "Our CNN-LSTM model consists of an initial LSTM layer which will receive word embeddings for each token in the tweet as inputs. The intuition is that its output tokens will store information not only of the initial token, but also any previous tokens; In other words, the LSTM layer is generating a new encoding for the original input. The output of the LSTM layer is then fed into a convolution layer which we expect will extract local features. Finally the convolution layer’s output will be pooled to a smaller dimension and ultimately outputted as either a positive or negative label.\n",
    "\n",
    "![image.png](LSTM_CNN_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6caf3",
   "metadata": {},
   "source": [
    "### load needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fba29044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense,Input, Embedding,LSTM,Dropout,Conv1D, MaxPooling1D, GlobalMaxPooling1D,Dropout,Bidirectional,Flatten,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#import transformers\n",
    "#import tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66f24c",
   "metadata": {},
   "source": [
    "### load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0a7acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67212a4",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76ae6683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regard...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the ref...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Paren...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                            review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regard...   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the ref...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Paren...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action t...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60b098d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04c7cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92b89bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not solely cooking (which would have been great too). Very stimulating and captivating, always keeping the viewer peeking around the corner to see what was coming up next. She is as down to earth and as personable as you get, like one of us which made the show all the more enjoyable. Special guests, who are friends as well made for a nice surprise too...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                 review  \\\n",
       "count                                                                                                                                                                                                                                                                                                                                                                                                             50000   \n",
       "unique                                                                                                                                                                                                                                                                                                                                                                                                            49582   \n",
       "top     Loved today's show!!! It was a variety and not solely cooking (which would have been great too). Very stimulating and captivating, always keeping the viewer peeking around the corner to see what was coming up next. She is as down to earth and as personable as you get, like one of us which made the show all the more enjoyable. Special guests, who are friends as well made for a nice surprise too...   \n",
       "freq                                                                                                                                                                                                                                                                                                                                                                                                                  5   \n",
       "\n",
       "       sentiment  \n",
       "count      50000  \n",
       "unique         2  \n",
       "top     positive  \n",
       "freq       25000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a579e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c5c62",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28e365bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c478ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8d8c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9c36591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "683227a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfb6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "           \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "           \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \n",
    "           \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "           \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "           \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \n",
    "           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\n",
    "           \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "           \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "           \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "           \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "           \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \n",
    "           \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "           \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "           \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "           \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\n",
    "           \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \n",
    "           \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \n",
    "           \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \n",
    "           \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "           \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "           \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "           \"what'll\": \"what will\", \"what'll've\": \"what will have\",\"what're\": \"what are\",  \n",
    "           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \n",
    "           \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "           \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "           \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "           \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "           \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \n",
    "           \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \n",
    "           \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f39cba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Abdallah El-\n",
      "[nltk_data]     Sawy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "#function to clean data\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "def clean_text(text,lemmatize = True):\n",
    "    soup = BeautifulSoup(text, \"html.parser\") #remove html tags\n",
    "    text = soup.get_text()\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")]) #expanding chatwords and contracts clearing contractions\n",
    "    emoji_clean= re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_clean.sub(r'',text)\n",
    "    text = re.sub(r'\\.(?=\\S)', '. ',text) #add space after full stop\n",
    "    text = re.sub(r'http\\S+', '', text) #remove urls\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation]) #remove punctuation\n",
    "    #tokens = re.split('\\W+', text) #create tokens\n",
    "    if lemmatize:\n",
    "        text = \" \".join([wl.lemmatize(word) for word in text.split() if word not in stop and word.isalpha()]) #lemmatize\n",
    "    else:\n",
    "        text = \" \".join([word for word in text.split() if word not in stop and word.isalpha()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbe9551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']=data['review'].apply(clean_text,lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "142a7587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique unassuming oldtimebbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty character likable even well bread suspected serial killer may disappointed realize match point risk addiction thought proof woody allen still fully control style many u grown love would laughed one woodys comedy year dare say decade never impressed sca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie closet parent fighting time movie slower soap opera suddenly jake decides become rambo kill zombie ok first going make film must decide thriller drama drama movie watchable parent divorcing arguing like real life jake closet totally ruin film expected see boogeyman similar movie instead watched drama meaningless thriller spot well playing parent de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunning film watch mr mattei offer u vivid portrait human relation movie seems telling u money power success people different situation encounter variation arthur schnitzlers play theme director transfer action present time new york different character meet connect one connected one way another next person one seems know previous point contact stylishly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                            review  \\\n",
       "0  one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwar...   \n",
       "1  wonderful little production filming technique unassuming oldtimebbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come ...   \n",
       "2  thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty character likable even well bread suspected serial killer may disappointed realize match point risk addiction thought proof woody allen still fully control style many u grown love would laughed one woodys comedy year dare say decade never impressed sca...   \n",
       "3  basically family little boy jake think zombie closet parent fighting time movie slower soap opera suddenly jake decides become rambo kill zombie ok first going make film must decide thriller drama drama movie watchable parent divorcing arguing like real life jake closet totally ruin film expected see boogeyman similar movie instead watched drama meaningless thriller spot well playing parent de...   \n",
       "4  petter matteis love time money visually stunning film watch mr mattei offer u vivid portrait human relation movie seems telling u money power success people different situation encounter variation arthur schnitzlers play theme director transfer action present time new york different character meet connect one connected one way another next person one seems know previous point contact stylishly...   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting target variable to numeric labels\n",
    "data.sentiment = [ 1 if each == \"positive\" else 0 for each in data.sentiment]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f964208",
   "metadata": {},
   "source": [
    "#### Spliting the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecee2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39665,) (39665,)\n",
      "(9917,) (9917,)\n"
     ]
    }
   ],
   "source": [
    "#splitting into train and test\n",
    "train, test= train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "#train dataset\n",
    "Xtrain, ytrain = train['review'], train['sentiment']\n",
    "\n",
    "#test dataset\n",
    "Xtest, ytest = test['review'], test['sentiment']\n",
    "\n",
    "print(Xtrain.shape,ytrain.shape)\n",
    "print(Xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196a120",
   "metadata": {},
   "source": [
    "#### Vectorizing data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "771a78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "Xtrain_vect= vect.fit_transform(Xtrain)\n",
    "Xtest_vect = vect.transform(Xtest)\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer() \n",
    "Xtrain_count = count_vect.fit_transform(Xtrain)\n",
    "Xtest_count = count_vect.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af51d6",
   "metadata": {},
   "source": [
    "# 1- LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c529e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of the dataset is :  126096\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE,oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(Xtrain)\n",
    "word_index = tokenizer.word_index\n",
    "#print(word_index)\n",
    "V = len(word_index)\n",
    "print(\"Vocabulary of the dataset is : \",V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0aadcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create sequences of reviews\n",
    "seq_train = tokenizer.texts_to_sequences(Xtrain)\n",
    "seq_test =  tokenizer.texts_to_sequences(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69615d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of sequence in the list: 1406\n"
     ]
    }
   ],
   "source": [
    "#choice of maximum length of sequences\n",
    "seq_len_list = [len(i) for i in seq_train + seq_test]\n",
    "\n",
    "#if we take the direct maximum then\n",
    "max_len=max(seq_len_list)\n",
    "print('Maximum length of sequence in the list: {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b416d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of the sequence when considering data only two standard deviations from average: 293\n"
     ]
    }
   ],
   "source": [
    "# when setting the maximum length of sequence, variability around the average is used.\n",
    "max_seq_len = np.mean(seq_len_list) + 2 * np.std(seq_len_list)\n",
    "max_seq_len = int(max_seq_len)\n",
    "print('Maximum length of the sequence when considering data only two standard deviations from average: {}'.format(max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6cba2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above calculated number coveres approximately 94.51 % of data\n"
     ]
    }
   ],
   "source": [
    "perc_covered = np.sum(np.array(seq_len_list) < max_seq_len) / len(seq_len_list)*100\n",
    "print('The above calculated number coveres approximately {} % of data'.format(np.round(perc_covered,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e9dfd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create padded sequences\n",
    "pad_train=pad_sequences(seq_train,truncating = 'post', padding = 'pre',maxlen=max_seq_len)\n",
    "pad_test=pad_sequences(seq_test,truncating = 'post', padding = 'pre',maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad37542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training set for validation purposes\n",
    "Xtrain,Xval,ytrain,yval=train_test_split(pad_train,ytrain,\n",
    "                                             test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3d918f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(Xtrain,Xval,ytrain,yval,V,D,maxlen,epochs):\n",
    "\n",
    "    print(\"----Building the model----\")\n",
    "    i = Input(shape=(maxlen,))\n",
    "    x = Embedding(V + 1, D,input_length = maxlen)(i)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv1D(32,5,activation = 'relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(i, x)\n",
    "    model.summary()\n",
    "\n",
    "    #Training the LSTM\n",
    "    print(\"----Training the network----\")\n",
    "    model.compile(optimizer= Adam(0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    r = model.fit(Xtrain,ytrain, \n",
    "                  validation_data = (Xval,yval), \n",
    "                  epochs = epochs, \n",
    "                  verbose = 2,\n",
    "                  batch_size = 32)\n",
    "                  #callbacks = callbacks\n",
    "    print(\"Train score:\", model.evaluate(Xtrain,ytrain))\n",
    "    print(\"Validation score:\", model.evaluate(Xval,yval))\n",
    "    n_epochs = len(r.history['loss'])\n",
    "    \n",
    "    return r,model,n_epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dbde9997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Building the model----\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 293)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 293, 64)           8070208   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 293, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 293, 64)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 289, 32)           10272     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 289, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 144, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 144, 256)         164864    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                82176     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,327,841\n",
      "Trainable params: 8,327,713\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "----Training the network----\n",
      "Epoch 1/5\n",
      "992/992 - 866s - loss: 0.4168 - accuracy: 0.8010 - val_loss: 0.2784 - val_accuracy: 0.8864 - 866s/epoch - 873ms/step\n",
      "Epoch 2/5\n",
      "992/992 - 808s - loss: 0.2524 - accuracy: 0.8988 - val_loss: 0.2713 - val_accuracy: 0.8923 - 808s/epoch - 815ms/step\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-499942220b57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m \u001b[1;31m#embedding dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-ecb16dc09c10>\u001b[0m in \u001b[0;36mlstm_model\u001b[1;34m(Xtrain, Xval, ytrain, yval, V, D, maxlen, epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#                            )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[1;31m#  callbacks = [checkpoints,early_stop]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     r = model.fit(Xtrain,ytrain, \n\u001b[0m\u001b[0;32m     34\u001b[0m                   \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                   \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D = 64 #embedding dims\n",
    "epochs = 3\n",
    "r,model,n_epochs = lstm_model(Xtrain,Xval,ytrain,yval,V,D,max_seq_len,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0347e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLearningCurve(history,epochs):\n",
    "    \n",
    "    epochRange = range(1,epochs+1)\n",
    "    fig , ax = plt.subplots(1,2,figsize = (10,5))\n",
    "  \n",
    "    ax[0].plot(epochRange,history.history['accuracy'],label = 'Training Accuracy')\n",
    "    ax[0].plot(epochRange,history.history['val_accuracy'],label = 'Validation Accuracy')\n",
    "    ax[0].set_title('Training and Validation accuracy')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(epochRange,history.history['loss'],label = 'Training Loss')\n",
    "    ax[1].plot(epochRange,history.history['val_loss'],label = 'Validation Loss')\n",
    "    ax[1].set_title('Training and Validation loss')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb2d70f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-aa921e8f0a3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplotLearningCurve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "plotLearningCurve(r,n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24205b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Model Performance on Test set\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5a585615ba8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluate Model Performance on Test set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate Model Performance on Test set\")\n",
    "result = model.evaluate(pad_test,ytest)\n",
    "print(dict(zip(model.metrics_names, result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdc53a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-7413947547ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Generate predictions for the test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Get the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Generate predictions for the test dataset\n",
    "ypred = model.predict(pad_test)\n",
    "ypred = ypred>0.5\n",
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(ytest, ypred)\n",
    "sns.heatmap(cf_matrix,annot = True,fmt ='g', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b9818",
   "metadata": {},
   "source": [
    "# 2-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "98605a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, MaxPool1D, Dropout, SimpleRNN, LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f6bed697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = df.sentiment.map({ 'negative': 0, 'positive': 1 })\n",
    "\n",
    "text = df.review.tolist()\n",
    "label = df.sentiment.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "04dd32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "51c6efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "62d0a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = []\n",
    "X_test_clean = []\n",
    "clean = re.compile(r'<[^>]+>')\n",
    "for i, test in enumerate(X_train):\n",
    "    tmp_text = test.lower()\n",
    "    tmp_text = tmp_text.replace('\\n', '')\n",
    "    tmp_text = clean.sub('', tmp_text)\n",
    "    tmp_text = tmp_text.translate(translator)\n",
    "    X_train_clean.append(tmp_text)\n",
    "\n",
    "for i, test in enumerate(X_test):\n",
    "    tmp_text = test.lower()\n",
    "    tmp_text = tmp_text.replace('\\n', '')\n",
    "    tmp_text = clean.sub('', tmp_text)\n",
    "    tmp_text = tmp_text.translate(translator)\n",
    "    X_test_clean.append(tmp_text)\n",
    "\n",
    "X_train_clean = np.array(X_train_clean)\n",
    "X_test_clean = np.array(X_test_clean)\n",
    "\n",
    "X_train = X_train_clean\n",
    "X_test = X_test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e39d845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 40000\n",
    "tokenizer = Tokenizer(num_words=top_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6ea036fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 100\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words, padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "79ae54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1dbded0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 100)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5e1b5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000,32, input_length=100))\n",
    "model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "790d38f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 32)           640000    \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 100, 256)          24832     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 50, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 50, 256)           0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 50, 128)           98432     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 25, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 25, 128)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 250)               800250    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,563,765\n",
      "Trainable params: 1,563,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c894af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[115,1] = 25617 is not in [0, 20000)\n\t [[node sequential_9/embedding_7/embedding_lookup\n (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:191)\n]] [Op:__inference_train_function_24668]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_9/embedding_7/embedding_lookup:\nIn[0] sequential_9/embedding_7/embedding_lookup/24289:\t\nIn[1] sequential_9/embedding_7/Cast (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-194-5f3d6bbf1eb8>\", line 1, in <module>\n>>>     model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size=128, verbose=2)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-5f3d6bbf1eb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[115,1] = 25617 is not in [0, 20000)\n\t [[node sequential_9/embedding_7/embedding_lookup\n (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:191)\n]] [Op:__inference_train_function_24668]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_9/embedding_7/embedding_lookup:\nIn[0] sequential_9/embedding_7/embedding_lookup/24289:\t\nIn[1] sequential_9/embedding_7/Cast (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-194-5f3d6bbf1eb8>\", line 1, in <module>\n>>>     model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size=128, verbose=2)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b1c02",
   "metadata": {},
   "source": [
    "# 3- LSTM-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a4b5dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000,32, input_length=100))\n",
    "model.add(Conv1D(256, 3, activation='relu', input_shape=(178, 1), padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "91288781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 32)           640000    \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 100, 256)          24832     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 50, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 50, 256)           0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 50, 128)           98432     \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 25, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 25, 128)           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 25, 64)            49408     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 250)               8250      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833,589\n",
      "Trainable params: 833,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "aa696ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[81,20] = 32214 is not in [0, 20000)\n\t [[node sequential_10/embedding_8/embedding_lookup\n (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:191)\n]] [Op:__inference_train_function_30735]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_10/embedding_8/embedding_lookup:\nIn[0] sequential_10/embedding_8/embedding_lookup/28382:\t\nIn[1] sequential_10/embedding_8/Cast (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-197-5f3d6bbf1eb8>\", line 1, in <module>\n>>>     model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size=128, verbose=2)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-5f3d6bbf1eb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[81,20] = 32214 is not in [0, 20000)\n\t [[node sequential_10/embedding_8/embedding_lookup\n (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:191)\n]] [Op:__inference_train_function_30735]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_10/embedding_8/embedding_lookup:\nIn[0] sequential_10/embedding_8/embedding_lookup/28382:\t\nIn[1] sequential_10/embedding_8/Cast (defined at C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-197-5f3d6bbf1eb8>\", line 1, in <module>\n>>>     model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size=128, verbose=2)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Abdallah El-Sawy\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723179d",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- http://konukoii.com/blog/2018/02/19/twitter-sentiment-analysis-using-combined-lstm-cnn-models/\n",
    "- https://arxiv.org/pdf/1408.5882.pdf\n",
    "- https://github.com/pytorch/ignite/blob/master/examples/notebooks/TextCNN.ipynb\n",
    "- https://www.kaggle.com/raghav2002sharma/sentiment-classifier-with-cnn-bi-lstm\n",
    "- https://www.kaggle.com/ashrafkhan94/imdb-review-comparison-using-cnn-lstm-bert\n",
    "- https://www.kaggle.com/parth05rohilla/bi-lstm-and-cnn-model-top-10/notebook\n",
    "- https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/code?competitionId=10025&searchQuery=cnn\n",
    "- https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_natural-language-processing-applications/sentiment-analysis-cnn.ipynb\n",
    "- https://www.kaggle.com/nafisur/keras-models-lstm-cnn-gru-bidirectional-glove\n",
    "- https://www.kaggle.com/derrelldsouza/imdb-sentiment-analysis-eda-ml-lstm-bert#5.-Predictive-Modelling-using-Deep-Learning\n",
    "- https://www.kaggle.com/clementbrehard/imdb-conv1d-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8334638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
